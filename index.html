<html>

<head>
  <title>RR Audio Demo</title>
</head>

<body style="font-family: Verdana, Geneva, Tahoma, sans-serif; background: rgb(2,0,36);
background: linear-gradient(180deg, #3498db 0, #3498db 125px, #2980b9 125px, #2980b9 135px, #ecf0f1 135px, #ecf0f1 235px, #8E44AD 235px, #8E44AD 245px, #9B59B6 245px, #9B59B6 100%);">
  <div style="width: 1000px; margin: 0px auto;">
    <h1 style="padding: 20px; text-align: center; color: #ecf0f1;">Remote Rhapsody Team 37 Audio Demo</h1>
    <canvas id="spectrogram_vis" height="100" width="1000" style="margin-top: -80px;"></canvas>
    <div style="line-height: 100px; text-align: center; height: 100px; margin-top: 7px;">Please enable microphone access and make sounds into your microphone</div>
    <!--<button type="button" onclick="init()"
      style="display: block; margin: 10px auto; width: 200px; height: 40px;">Start</button>-->
    
    <div id="label-container" style="display: flex; margin-top: 20px;"></div>
    <div id="prediction-container" style="margin-top: 20px; line-height: 100px; text-align: center; height: 100px; ">
      Please wait while the page is loading :)
    </div>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script
      src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>

    <script type="text/javascript">
      // more documentation available at
      // https://github.com/tensorflow/tfjs-models/tree/master/speech -commands

      // the link to your model provided by Teachable Machine export panel
      const URL = "https://rr.melde.net/model/";
      spectrogram_vis_canvas = document.getElementById("spectrogram_vis");
      pred_cont = document.getElementById("prediction-container");
      ctx = spectrogram_vis_canvas.getContext('2d')
      ctx.strokeStyle = "#2980b9";
      ctx.lineWidth = 2;


      async function createModel() {
        const checkpointURL = URL + "model.json"; // model topology
        const metadataURL = URL + "metadata.json"; // model metadata

        const recognizer = speechCommands.create(
          "BROWSER_FFT", // fourier transform type, not useful to change
          undefined, // speech commands vocabulary feature, not useful for your models
          checkpointURL,
          metadataURL);

        // check that model and metadata are loaded via HTTPS requests.
        await recognizer.ensureModelLoaded();

        return recognizer;
      }

      if (!Float32Array.prototype.slice) {
        Float32Array.prototype.slice = function (begin, end) {
          var target = new Float32Array(end - begin);

          for (var i = 0; i < begin + end; ++i) {
            target[i] = this[begin + i];
          }
          return target;
        };
      }

      async function init() {
        const recognizer = await createModel();
        const classLabels = recognizer.wordLabels(); // get class labels
        const labelContainer = document.getElementById("label-container");
        for (let i = 0; i < classLabels.length; i++) {
          div_elem = document.createElement("div");
          div_elem.style = "margin: auto;" //" margin-right: 10px; margin-top: 5px;"
          labelContainer.appendChild(div_elem);
        }

        // listen() takes two arguments:
        // 1. A callback function that is invoked anytime a word is recognized.
        // 2. A configuration object with adjustable fields
        recognizer.listen(result => {
          const scores = result.scores; // probability of prediction for each class
          ctx.clearRect(0, 0, spectrogram_vis_canvas.width, spectrogram_vis_canvas.height);
          for (let i = 0; i < spectrogram_vis_canvas.width; i++) {
            ctx.beginPath();
            ctx.moveTo(i, spectrogram_vis_canvas.height);
            ctx.lineTo(i, result.spectrogram.data[i] * -1 / 1.4 );
            ctx.stroke();
          }
          // render the probability scores per class
          max_label = "silent"
          max_score = 0
          for (let i = 0; i < classLabels.length; i++) {
            const score = Math.trunc(result.scores[i].toFixed(2)*100)
            const classPrediction = classLabels[i] + ":<br/>" + score+ "%";
            labelContainer.childNodes[i].innerHTML = classPrediction;
            labelContainer.childNodes[i].style = "margin: auto; background: linear-gradient(90deg, #3498db 0%, #3498db "+ score +"%, #9B59B6 "+ score +"%, #9B59B6 100%)"
            if (score > max_score) {
              max_label = classLabels[i]
              max_score = score
            }
          }
          pred_cont.innerHTML = "We are " + max_score + " percent sure you made a <b>" + max_label + "</b> sound.";
        }, {
          includeSpectrogram: true, // in case listen should return result.spectrogram
          probabilityThreshold: 0.75,
          invokeCallbackOnNoiseAndUnknown: true,
          overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
        });

        // Stop the recognition in 5 seconds.
        // setTimeout(() => recognizer.stopListening(), 5000);
      }
    </script>
    <script>init()</script>
  </div>
</body>

</html>